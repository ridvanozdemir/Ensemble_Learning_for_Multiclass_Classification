{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_EnsembleLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPDuj9dWJdM"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub4LWBZ6Wdu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d50d7a7-4908-4453-eea1-7ec336e78739"
      },
      "source": [
        "%cd /content/drive/My Drive/task/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOh40RwzWrjz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LassoCV\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from vecstack import stacking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiSf9z5BbVk0"
      },
      "source": [
        "!pip install vecstack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ppIW7-YYH-"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGQ_WOwXz0mG"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlsvSQSExL8g"
      },
      "source": [
        "#creating a DL model for multiclass classification \n",
        "def build_keras_model_1():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, \n",
        "                    input_dim=X_train.shape[1], \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='relu'))\n",
        "    model.add(Dense(64, \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='relu'))\n",
        "    model.add(Dense(64, \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='relu'))\n",
        "    model.add(Dense(64, \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='relu'))\n",
        "    model.add(Dense(9, \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='softmax'))\n",
        "    model.compile(optimizer='rmsprop', \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['categorical_accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM5uFE0Emk3D"
      },
      "source": [
        "# Create list: stacked_models\n",
        "stacked_models = [LogisticRegression(random_state=42),\n",
        "                  KNeighborsClassifier(),\n",
        "                  CatBoostClassifier(random_state=42),\n",
        "                  BaggingClassifier(random_state=42,n_jobs=-1),\n",
        "                  MLPClassifier(random_state=42),\n",
        "                  AdaBoostClassifier(random_state=42),\n",
        "                  SVC(probability=True, random_state=42),\n",
        "                  DecisionTreeClassifier(random_state=42),\n",
        "                  KerasClassifier(build_fn=build_keras_model_1, epochs=20, batch_size=32, verbose=2),\n",
        "                  LGBMClassifier(random_state=42,n_jobs=-1)]\n",
        "\n",
        "#reading training dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "#statistic information of dataset\n",
        "df.head()\n",
        "df.describe().T\n",
        "\n",
        "#checking missing data\n",
        "df.isnull().sum()\n",
        "\n",
        "#spliting dependent and independent variables\n",
        "y = df[\"target\"]\n",
        "X = df.drop([\"target\"], axis= 1)\n",
        "\n",
        "#spliting test and train datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "\n",
        "#scaling the dataset\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#reading validation dataset\n",
        "df_test = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "# Stack the models: stack_train, stack_test\n",
        "stack_train, stack_test = stacking(stacked_models, X_train, y_train, X_test, \n",
        "                                   regression=False, mode= 'oof_pred_bag',\n",
        "                                   needs_proba=True, metric=log_loss, \n",
        "                                   n_folds=5, stratified=True, shuffle=True, \n",
        "                                   random_state=42, verbose=2)\n",
        "\n",
        "# Initialize and fit 2nd level model\n",
        "#final_model = XGBClassifier(n_estimators= 500, max_depth=30, learning_rate=0.01, random_state=42, n_jobs=-1) #0.52\n",
        "final_model = XGBClassifier(random_state=42, n_jobs=-1)\n",
        "final_model_fit = final_model.fit(stack_train, y_train)\n",
        "# Predict: stacked_pred\n",
        "\n",
        "y_pred = final_model.predict_proba(stack_test)\n",
        "#y_pred_test = final_model.predict_proba(df_test)\n",
        "\n",
        "#measuring the error\n",
        "log_loss(y_test, y_pred)\n",
        "print(log_loss(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}